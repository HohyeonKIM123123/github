from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
import time
import csv
from datetime import datetime
import urllib.parse

def crawl_han():
    """í•œê²½ê¸€ë¡œë²Œ ë§ˆì¼“ í¬ë¡¤ë§"""
    
    # Chrome ì„¤ì •
    options = Options()
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    
    driver = webdriver.Chrome(options=options)
    
    try:
        print("ğŸš€ í•œê²½ê¸€ë¡œë²Œë§ˆì¼“ í¬ë¡¤ë§ ì‹œì‘...")
        
        # 1. í•œê²½ ë©”ì¸ í˜ì´ì§€ ì ‘ì†
        print("ğŸ“° í•œê²½ ë©”ì¸ í˜ì´ì§€ ì ‘ì† ì¤‘...")
        driver.get("https://www.hankyung.com/globalmarket/news-globalmarket")
        time.sleep(3)
        
        # ë‰´ìŠ¤ ë§í¬ ìˆ˜ì§‘
        news_list = []                           
        
        # HTML ë¬¸ì„œì—ì„œ ëª¨ë“  <a> íƒœê·¸ë¥¼ ì„ íƒí•¨
        links = driver.find_elements(By.XPATH, "//ul[@class='news-list']/li//h2[@class='news-tit']/a")
        
        for i, link in enumerate(links[:10]):  # ìƒìœ„ 10ê°œë§Œ
            try:
                title = link.text.strip()
                url = link.get_attribute('href')
                
                # ì´ë¯¸ì§€ URL ì¶”ì¶œ (photo íƒœê·¸ ìš°ì„ )
                img_url = "ì´ë¯¸ì§€ ì—†ìŒ"  # ê¸°ë³¸ ê°’ ì„¤ì •
                try:
                    # 1. ì‚¬ì§„ (photo) ê´€ë ¨ ì´ë¯¸ì§€ ì¶”ì¶œ
                    img_el = link.find_element(By.XPATH, ".//ancestor::li//img[contains(@src, 'photo')]")
                    img_url = img_el.get_attribute("src")
                    
                    # ì´ë¯¸ì§€ URLì„ ë””ì½”ë”©í•˜ì—¬ ì¶”ì¶œëœ ë§í¬ë¥¼ ì‹¤ì œ ì´ë¯¸ì§€ ë§í¬ë¡œ
                    img_url = urllib.parse.unquote(img_url)  # ë””ì½”ë”© ì²˜ë¦¬
                    
                    # ë¶ˆí•„ìš”í•œ ì•„ì´ì½˜ ì´ë¯¸ì§€ (ì˜ˆ: íšŒì› ì „ìš© ì´ë¯¸ì§€) ì œì™¸
                    if 'icon' in img_url or 'svg' in img_url:
                        img_url = "ì´ë¯¸ì§€ ì—†ìŒ"
                    print(f"ğŸ–¼ï¸ ì¶”ì¶œëœ ì´ë¯¸ì§€ URL: {img_url}")
                except Exception as e:
                    print(f"âš ï¸ ì´ë¯¸ì§€ URL ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                
                if title and url and len(title) > 10:  # ìœ íš¨í•œ ì œëª©ë§Œ
                    news_list.append({
                        'index': len(news_list) + 1,
                        'title': title,
                        'link': url,
                        'time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        'image': img_url
                    })
                    print(f"ğŸ“° [{len(news_list)}] {title[:50]}... (ì´ë¯¸ì§€: {img_url})")
            except Exception as e:
                print(f"âš ï¸ ë‰´ìŠ¤ í•­ëª© ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue
        
        return news_list
        
    except Exception as e:
        print(f"âŒ ì—ëŸ¬: {e}")
        return []
    finally:
        driver.quit()

def save_csv(news_list):
    """CSV íŒŒì¼ ì €ì¥"""
    if not news_list:
        print("âŒ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    filename = f"it_news_{datetime.now().strftime('%Y%m%d_%H%M')}.csv"
    
    with open(filename, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.writer(f)
        
        # CSV íŒŒì¼ í—¤ë”
        writer.writerow(['index', 'title', 'link', 'time'])  # ì²« ë²ˆì§¸ ì¤„: ì œëª© ì •ë³´
        
        # ë‰´ìŠ¤ ë°ì´í„°
        for item in news_list:
            writer.writerow([item['index'], item['title'], item['link'], item['time']])  # ì²« ë²ˆì§¸ ì¤„ (ì œëª©)
            writer.writerow([item['image']])  # ë‘ ë²ˆì§¸ ì¤„ (ì´ë¯¸ì§€ URL)
    
    print(f"âœ… ì €ì¥ì™„ë£Œ: {filename} ({len(news_list)}ê°œ)")

def main():
    # í¬ë¡¤ë§ ì‹¤í–‰
    news = crawl_han()
    
    # ê²°ê³¼ ì¶œë ¥
    if news:
        print(f"\nğŸ“Š ì´ {len(news)}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘ì™„ë£Œ!")
        save_csv(news)
    else:
        print("âŒ ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()